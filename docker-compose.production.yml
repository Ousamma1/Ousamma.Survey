version: '3.8'

services:
  # ============================================
  # Infrastructure Services
  # ============================================

  # Zookeeper for Kafka Coordination
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: survey-zookeeper
    restart: always
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_MAX_CLIENT_CNXNS: 60
      ZOOKEEPER_AUTOPURGE_SNAP_RETAIN_COUNT: 3
      ZOOKEEPER_AUTOPURGE_PURGE_INTERVAL: 24
    ports:
      - "2181:2181"
    networks:
      - survey-network
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,environment"

  # Kafka Message Broker
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: survey-kafka
    restart: always
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_COMPRESSION_TYPE: 'snappy'
      KAFKA_MAX_REQUEST_SIZE: 1048576
    ports:
      - "9092:9092"
      - "29092:29092"
    networks:
      - survey-network
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Kafka UI for Monitoring
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: survey-kafka-ui
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_CLUSTERS_0_NAME: survey-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      LOGGING_LEVEL_ROOT: WARN
      LOGGING_LEVEL_COM_PROVECTUS: INFO
    ports:
      - "8080:8080"
    networks:
      - survey-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # MongoDB Database
  mongodb:
    image: mongo:7.0
    container_name: survey-mongodb
    restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USERNAME:-admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD:-changeme}
      MONGO_INITDB_DATABASE: survey_platform
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
      - mongodb_config:/data/configdb
      - ./scripts/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    networks:
      - survey-network
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: survey-redis
    restart: always
    command: >
      redis-server
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
      --appendfsync everysec
    ports:
      - "6379:6379"
    networks:
      - survey-network
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ============================================
  # Application Services
  # ============================================

  # Survey Service (Main Application)
  survey-service:
    build:
      context: .
      dockerfile: Dockerfile.optimized
      args:
        NODE_ENV: production
    container_name: survey-service
    restart: always
    environment:
      - NODE_ENV=production
      - PORT=3000
      - AI_PROVIDER=${AI_PROVIDER:-openai}
      - AI_API_URL=${AI_API_URL}
      - AI_MODEL=${AI_MODEL:-gpt-4}
      - GEOLOCATION_SERVICE_URL=http://geolocation-service:3001
      - KAFKA_BROKERS=kafka:9092
      - MONGODB_URI=mongodb://${MONGO_ROOT_USERNAME:-admin}:${MONGO_ROOT_PASSWORD:-changeme}@mongodb:27017
      - LOG_LEVEL=${LOG_LEVEL:-info}
    env_file:
      - .env.production
    ports:
      - "3000:3000"
    depends_on:
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_healthy
      geolocation-service:
        condition: service_healthy
    networks:
      - survey-network
    volumes:
      - survey_uploads:/app/uploads
      - survey_data:/app/data
      - survey_public:/app/public
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3000/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"
        labels: "service=survey-service,environment=production"

  # Geolocation Service
  geolocation-service:
    build:
      context: ./services/geolocation-service
      dockerfile: Dockerfile.optimized
    container_name: geolocation-service
    restart: always
    environment:
      - NODE_ENV=production
      - PORT=3001
      - MONGODB_URI=mongodb://${MONGO_ROOT_USERNAME:-admin}:${MONGO_ROOT_PASSWORD:-changeme}@mongodb:27017/geolocation
      - MONGODB_DB_NAME=geolocation
      - GEOCODER_PROVIDER=openstreetmap
      - ALLOWED_ORIGINS=http://localhost:3000
      - DEFAULT_ACCURACY_THRESHOLD=100
      - MAX_LOCATION_HISTORY=1000
      - LOG_LEVEL=${LOG_LEVEL:-info}
    env_file:
      - ./services/geolocation-service/.env.production
    ports:
      - "3001:3001"
    depends_on:
      mongodb:
        condition: service_healthy
    networks:
      - survey-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3001/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Analytics Service
  analytics-service:
    build:
      context: ./services/analytics-service
      dockerfile: Dockerfile.optimized
    container_name: analytics-service
    restart: always
    environment:
      - NODE_ENV=production
      - PORT=3002
      - MONGODB_URI=mongodb://${MONGO_ROOT_USERNAME:-admin}:${MONGO_ROOT_PASSWORD:-changeme}@mongodb:27017/analytics
      - MONGODB_DB_NAME=analytics
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_TTL=3600
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_CLIENT_ID=analytics-service
      - KAFKA_GROUP_ID=analytics-group
      - CACHE_WARMING_ENABLED=true
      - CACHE_TTL_HOT_DATA=300
      - CACHE_TTL_COLD_DATA=3600
      - LOG_LEVEL=${LOG_LEVEL:-info}
    env_file:
      - ./services/analytics-service/.env.production
    ports:
      - "3002:3002"
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - survey-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3002/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: '0.75'
          memory: 768M
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Analytics Consumer Service
  analytics-consumer-service:
    build:
      context: ./services/analytics-consumer-service
      dockerfile: Dockerfile.optimized
    container_name: analytics-consumer-service
    restart: always
    environment:
      - NODE_ENV=production
      - PORT=3003
      - MONGODB_URI=mongodb://${MONGO_ROOT_USERNAME:-admin}:${MONGO_ROOT_PASSWORD:-changeme}@mongodb:27017/analytics
      - MONGODB_DB_NAME=analytics
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_CLIENT_ID=analytics-consumer
      - KAFKA_GROUP_ID=analytics-consumer-group
      - KAFKA_TOPICS=response.submitted,survey.created,survey.updated
      - BATCH_SIZE=100
      - BATCH_TIMEOUT=5000
      - LOG_LEVEL=${LOG_LEVEL:-info}
    env_file:
      - ./services/analytics-consumer-service/.env.production
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - survey-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3003/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Notification Service
  notification-service:
    build:
      context: ./services/notification-service
      dockerfile: Dockerfile.optimized
    container_name: notification-service
    restart: always
    environment:
      - NODE_ENV=production
      - PORT=3006
      - MONGODB_URI=mongodb://${MONGO_ROOT_USERNAME:-admin}:${MONGO_ROOT_PASSWORD:-changeme}@mongodb:27017/notifications
      - MONGODB_DB_NAME=notifications
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_CLIENT_ID=notification-service
      - KAFKA_GROUP_ID=notification-service-group
      - WEBSOCKET_URL=http://websocket-service:3002
      - LOG_LEVEL=${LOG_LEVEL:-info}
    env_file:
      - ./services/notification-service/.env.production
    ports:
      - "3006:3006"
    depends_on:
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - survey-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3006/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Notification Consumer Service
  notification-consumer-service:
    build:
      context: ./services/notification-consumer-service
      dockerfile: Dockerfile.optimized
    container_name: notification-consumer-service
    restart: always
    environment:
      - NODE_ENV=production
      - PORT=3004
      - MONGODB_URI=mongodb://${MONGO_ROOT_USERNAME:-admin}:${MONGO_ROOT_PASSWORD:-changeme}@mongodb:27017/notifications
      - MONGODB_DB_NAME=notifications
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_CLIENT_ID=notification-consumer
      - KAFKA_GROUP_ID=notification-consumer-group
      - EMAIL_PROVIDER=${EMAIL_PROVIDER:-smtp}
      - EMAIL_FROM=${EMAIL_FROM}
      - SMS_PROVIDER=${SMS_PROVIDER:-twilio}
      - PUSH_PROVIDER=${PUSH_PROVIDER:-fcm}
      - WEBSOCKET_URL=http://websocket-service:3002
      - MAX_RETRY_ATTEMPTS=3
      - RETRY_DELAY_MS=5000
      - LOG_LEVEL=${LOG_LEVEL:-info}
    env_file:
      - ./services/notification-consumer-service/.env.production
    depends_on:
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - survey-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3004/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Audit Consumer Service
  audit-consumer-service:
    build:
      context: ./services/audit-consumer-service
      dockerfile: Dockerfile.optimized
    container_name: audit-consumer-service
    restart: always
    environment:
      - NODE_ENV=production
      - PORT=3005
      - MONGODB_URI=mongodb://${MONGO_ROOT_USERNAME:-admin}:${MONGO_ROOT_PASSWORD:-changeme}@mongodb:27017/audit
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_CLIENT_ID=audit-consumer
      - KAFKA_GROUP_ID=audit-consumer-group
      - AUDIT_RETENTION_DAYS=365
      - LOG_LEVEL=${LOG_LEVEL:-info}
    env_file:
      - ./services/audit-consumer-service/.env.production
    depends_on:
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - survey-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3005/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # WebSocket Service
  websocket-service:
    build:
      context: ./services/websocket-service
      dockerfile: Dockerfile.optimized
    container_name: websocket-service
    restart: always
    environment:
      - NODE_ENV=production
      - PORT=3002
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_CLIENT_ID=websocket-service
      - KAFKA_GROUP_ID=websocket-consumers
      - JWT_SECRET=${JWT_SECRET}
      - HEARTBEAT_INTERVAL=30000
      - CONNECTION_TIMEOUT=60000
      - MAX_CONNECTIONS_PER_IP=10
      - RATE_LIMIT_WINDOW=60000
      - RATE_LIMIT_MAX_MESSAGES=100
      - LOG_LEVEL=${LOG_LEVEL:-info}
    env_file:
      - ./services/websocket-service/.env.production
    ports:
      - "3008:3002"
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - survey-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3002/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Project Service
  project-service:
    build:
      context: ./services/project-service
      dockerfile: Dockerfile.optimized
    container_name: project-service
    restart: always
    environment:
      - NODE_ENV=production
      - PORT=3009
      - MONGODB_URI=mongodb://${MONGO_ROOT_USERNAME:-admin}:${MONGO_ROOT_PASSWORD:-changeme}@mongodb:27017/projects
      - MONGODB_DB_NAME=projects
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_TTL=300
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_CLIENT_ID=project-service
      - KAFKA_GROUP_ID=project-service-group
      - CACHE_ENABLED=true
      - CACHE_TTL=300
      - LOG_LEVEL=${LOG_LEVEL:-info}
    env_file:
      - ./services/project-service/.env.production
    ports:
      - "3009:3009"
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - survey-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3009/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 20s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Admin Service
  admin-service:
    build:
      context: ./services/admin-service
      dockerfile: Dockerfile.optimized
    container_name: admin-service
    restart: always
    environment:
      - NODE_ENV=production
      - PORT=3007
      - MONGODB_URI=mongodb://${MONGO_ROOT_USERNAME:-admin}:${MONGO_ROOT_PASSWORD:-changeme}@mongodb:27017/admin_service
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_CLIENT_ID=admin-service
      - KAFKA_GROUP_ID=admin-service-group
      - HEALTH_CHECK_INTERVAL=30000
      - STATS_CACHE_TTL=60
      - AUDIT_RETENTION_DAYS=365
      - SURVEY_SERVICE_URL=http://survey-service:3000
      - GEOLOCATION_SERVICE_URL=http://geolocation-service:3001
      - ANALYTICS_SERVICE_URL=http://analytics-service:3002
      - WEBSOCKET_SERVICE_URL=http://websocket-service:3002
      - PROJECT_SERVICE_URL=http://project-service:3009
      - LOG_LEVEL=${LOG_LEVEL:-info}
    env_file:
      - ./services/admin-service/.env.production
    ports:
      - "3007:3007"
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - survey-network
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3007/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '0.75'
          memory: 768M
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# ============================================
# Networks
# ============================================
networks:
  survey-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# ============================================
# Volumes
# ============================================
volumes:
  # Infrastructure
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  kafka_data:
    driver: local
  mongodb_data:
    driver: local
  mongodb_config:
    driver: local
  redis_data:
    driver: local

  # Application Data
  survey_uploads:
    driver: local
  survey_data:
    driver: local
  survey_public:
    driver: local
